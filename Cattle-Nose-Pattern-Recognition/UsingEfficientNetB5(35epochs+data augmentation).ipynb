{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bounDCuizJT",
        "outputId": "787a45ae-eada-4a0b-a0a4-340ef91aaa7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.16.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.7)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import efficientnet_b5, EfficientNet_B5_Weights\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import torch.optim as optim\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DRIVE_PATH = \"/content/drive/MyDrive\"\n",
        "CHECKPOINT_PATH = os.path.join(DRIVE_PATH, '35th_epoch.pth')\n",
        "STATE_PATH = os.path.join(DRIVE_PATH, 'cow_identification_state.json')\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "config = {\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 32,\n",
        "    \"embedding_dim\": 128,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"total_epochs\": 25,\n",
        "    \"freeze_epochs\": 5,\n",
        "    \"triplet_margin\": 1.5,\n",
        "    \"train_root\": os.path.join(DRIVE_PATH, 'train'),\n",
        "    \"val_root\": os.path.join(DRIVE_PATH, 'val'),\n",
        "    \"test_root\": os.path.join(DRIVE_PATH, 'test')\n",
        "}\n",
        "\n",
        "# --- DATA PREPARATION ---\n",
        "def save_state(state):\n",
        "    with open(STATE_PATH, 'w') as f:\n",
        "        json.dump(state, f)\n",
        "    print(f\"‚úÖ Data split state saved to {STATE_PATH}\")\n",
        "\n",
        "def load_state():\n",
        "    if os.path.exists(STATE_PATH):\n",
        "        with open(STATE_PATH, 'r') as f:\n",
        "            state = json.load(f)\n",
        "        print(f\"üîÅ Data split state loaded from {STATE_PATH}\")\n",
        "        return state['known_train_paths'], state['known_val_paths'], state['test_paths'], state['known_classes'], state['unknown_classes']\n",
        "    return None, None, None, None, None\n",
        "\n",
        "def create_data_splits(config, known_ratio=2/3, random_state=42):\n",
        "    known_train_paths_state, known_val_paths_state, test_paths_state, known_classes_state, unknown_classes_state = load_state()\n",
        "\n",
        "    if known_train_paths_state:\n",
        "        return known_train_paths_state, known_val_paths_state, test_paths_state, known_classes_state, unknown_classes_state\n",
        "\n",
        "    # 1. Load all paths from the three folders\n",
        "    all_train_paths = glob.glob(os.path.join(config['train_root'], '*', '*.jpg'))\n",
        "    all_val_paths = glob.glob(os.path.join(config['val_root'], '*', '*.jpg'))\n",
        "    all_test_paths = glob.glob(os.path.join(config['test_root'], '*', '*.jpg'))\n",
        "\n",
        "    # 2. Split train classes into known (2/3) and unknown (1/3)\n",
        "    unique_train_labels = list(set([p.split(os.sep)[-2] for p in all_train_paths]))\n",
        "    known_classes, unknown_classes = train_test_split(unique_train_labels, test_size=1-known_ratio, random_state=random_state)\n",
        "\n",
        "    # 3. Create the actual path lists\n",
        "    known_train_paths = [p for p in all_train_paths if p.split(os.sep)[-2] in known_classes]\n",
        "\n",
        "    # 4. Use val and test folders as-is\n",
        "    known_val_paths = all_val_paths\n",
        "    test_paths = all_test_paths\n",
        "\n",
        "    print(f\"Total train classes: {len(unique_train_labels)}\")\n",
        "    print(f\"Known classes (2/3 of train): {len(known_classes)}\")\n",
        "    print(f\"Unknown classes (1/3 of train): {len(unknown_classes)}\")\n",
        "    print(f\"Known train images (for training): {len(known_train_paths)}\")\n",
        "    print(f\"Validation images: {len(known_val_paths)}\")\n",
        "    print(f\"Test images: {len(test_paths)}\")\n",
        "\n",
        "    # 5. Save the state for consistency\n",
        "    state_to_save = {\n",
        "        'known_train_paths': known_train_paths,\n",
        "        'known_val_paths': known_val_paths,\n",
        "        'test_paths': test_paths,\n",
        "        'known_classes': known_classes,\n",
        "        'unknown_classes': unknown_classes\n",
        "    }\n",
        "    save_state(state_to_save)\n",
        "\n",
        "    return known_train_paths, known_val_paths, test_paths, known_classes, unknown_classes\n",
        "\n",
        "known_train_paths, known_val_paths, test_paths, known_classes, unknown_classes = create_data_splits(config)\n",
        "\n",
        "\n",
        "# --- DATASET & DATALOADER ---\n",
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.transform = transform\n",
        "        self.label_to_images = {}\n",
        "        for p in image_paths:\n",
        "            label = p.split(os.sep)[-2]\n",
        "            self.label_to_images.setdefault(label, []).append(p)\n",
        "        self.labels = list(self.label_to_images.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return 10000\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_label = random.choice(self.labels)\n",
        "        negative_label = random.choice([l for l in self.labels if l != anchor_label])\n",
        "        anchor_path = random.choice(self.label_to_images[anchor_label])\n",
        "        positive_path = random.choice(self.label_to_images[anchor_label])\n",
        "        negative_path = random.choice(self.label_to_images[negative_label])\n",
        "\n",
        "        def load(path):\n",
        "            img = cv2.imread(path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            return self.transform(image=img)['image']\n",
        "\n",
        "        return load(anchor_path), load(positive_path), load(negative_path)\n",
        "\n",
        "transform_eval = A.Compose([\n",
        "    A.Resize(config['img_size'], config['img_size']),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "val_dataset = TripletDataset(known_val_paths, transform=transform_eval)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4)\n",
        "\n",
        "transform_train = A.Compose([\n",
        "    A.Resize(config['img_size'], config['img_size']),\n",
        "    A.HorizontalFlip(p=0.5), # Flip horizontally with a 50% probability\n",
        "    A.RandomRotate90(p=0.5), # Randomly rotate by 90 degrees\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5), # Randomly change color properties\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "train_dataset = TripletDataset(known_train_paths, transform=transform_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "# --- MODEL & LOSS FUNCTIONS ---\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, freeze_backbone=True):\n",
        "        super().__init__()\n",
        "        weights = EfficientNet_B5_Weights.IMAGENET1K_V1\n",
        "        self.backbone = efficientnet_b5(weights=weights)\n",
        "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, embedding_dim)\n",
        "        )\n",
        "        if freeze_backbone:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return self.head(x)\n",
        "\n",
        "def triplet_loss(anchor, positive, negative, margin=config['triplet_margin']):\n",
        "    pos_dist = F.pairwise_distance(anchor, positive)\n",
        "    neg_dist = F.pairwise_distance(anchor, negative)\n",
        "    loss = torch.relu(pos_dist - neg_dist + margin)\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "# --- HELPER FUNCTIONS FOR CHECKPOINTING ---\n",
        "def save_checkpoint(model, optimizer, epoch, freeze_backbone, path):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'freeze_backbone': freeze_backbone,\n",
        "    }, path)\n",
        "    print(f\"üíæ Checkpoint saved after epoch {epoch}\")\n",
        "\n",
        "def load_checkpoint(model_class, optimizer_class, embedding_dim, lr, checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
        "    freeze = checkpoint.get('freeze_backbone', True)\n",
        "\n",
        "    model = model_class(embedding_dim=embedding_dim, freeze_backbone=freeze).to(DEVICE)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if freeze:\n",
        "        optimizer = optimizer_class(model.head.parameters(), lr=lr)\n",
        "    else:\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = True\n",
        "        optimizer = optimizer_class(model.parameters(), lr=lr * 0.1)\n",
        "\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print(f\"üîÅ Resumed from epoch {start_epoch} (freeze_backbone={freeze})\")\n",
        "    return model, optimizer, start_epoch, freeze\n",
        "\n",
        "def evaluate_val_loss(model, val_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for anc, pos, neg in val_loader:\n",
        "            anc, pos, neg = anc.to(DEVICE), pos.to(DEVICE), neg.to(DEVICE)\n",
        "            e_anc = model(anc)\n",
        "            e_pos = model(pos)\n",
        "            e_neg = model(neg)\n",
        "            loss = triplet_loss(e_anc, e_pos, e_neg)\n",
        "            total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
        "    model.train()\n",
        "    return avg_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJPKJSBWlpmi",
        "outputId": "b5f202dc-535e-4053-e825-620ec5450bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Data split state loaded from /content/drive/MyDrive/cow_identification_state.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model_class, train_loader, val_loader, embedding_dim, lr, checkpoint_path, total_epochs, freeze_epochs):\n",
        "\n",
        "    start_epoch = 0\n",
        "    eval_frequency = 5\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        model, optimizer, start_epoch, freeze_backbone = load_checkpoint(\n",
        "            model_class=model_class,\n",
        "            optimizer_class=optim.Adam,\n",
        "            embedding_dim=embedding_dim,\n",
        "            lr=lr,\n",
        "            checkpoint_path=checkpoint_path,\n",
        "        )\n",
        "        # Update the learning rate for the unfreeze phase if needed\n",
        "        if not freeze_backbone:\n",
        "            for g in optimizer.param_groups:\n",
        "                g['lr'] = lr * 0.1\n",
        "    else:\n",
        "        model = model_class(embedding_dim=embedding_dim, freeze_backbone=True).to(DEVICE)\n",
        "        optimizer = optim.Adam(model.head.parameters(), lr=lr)\n",
        "        freeze_backbone = True\n",
        "        print(\"üöÄ Starting training from scratch...\")\n",
        "\n",
        "    model.train()\n",
        "    # ÿ™ŸÜÿ∏€åŸÖÿßÿ™ ŸÜŸáÿß€å€å ÿ®ÿ±ÿß€å ⁄©ÿßŸáÿ¥ ŸÖÿµÿ±ŸÅ ÿ≠ÿßŸÅÿ∏Ÿá\n",
        "    unfreeze_batch_size = 4\n",
        "    accumulation_steps = 4\n",
        "    unfreeze_train_loader = DataLoader(train_loader.dataset, batch_size=unfreeze_batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "    print(f\"Starting training for {total_epochs} epochs from epoch {start_epoch+1}\")\n",
        "\n",
        "    current_loader = train_loader\n",
        "    for epoch in range(start_epoch, total_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{total_epochs} - Freeze backbone: {freeze_backbone}\")\n",
        "\n",
        "        # Switch to the smaller batch size for the unfreeze phase\n",
        "        if not freeze_backbone:\n",
        "            current_loader = unfreeze_train_loader\n",
        "\n",
        "        total_loss = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i, (anc, pos, neg) in enumerate(tqdm(current_loader)):\n",
        "            anc, pos, neg = anc.to(DEVICE), pos.to(DEVICE), neg.to(DEVICE)\n",
        "\n",
        "            e_anc = model(anc)\n",
        "            e_pos = model(pos)\n",
        "            e_neg = model(neg)\n",
        "            loss = triplet_loss(e_anc, e_pos, e_neg)\n",
        "\n",
        "            loss = loss / accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "            if (i + 1) % accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        avg_train_loss = total_loss / len(current_loader)\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % eval_frequency == 0 or (epoch + 1) == total_epochs:\n",
        "            val_loss = evaluate_val_loss(model, val_loader)\n",
        "        save_checkpoint(model, optimizer, epoch+1, freeze_backbone, checkpoint_path)\n",
        "\n",
        "\n",
        "        if freeze_backbone and (epoch + 1) >= freeze_epochs:\n",
        "            print(\"üîì Unfreezing backbone and updating optimizer...\")\n",
        "            # This part is crucial for memory management\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            freeze_backbone = False\n",
        "            for p in model.backbone.parameters():\n",
        "                p.requires_grad = True\n",
        "            optimizer = optim.Adam(model.parameters(), lr=lr * 0.1)\n",
        "\n",
        "    print(\"‚úÖ Training complete\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "0fR96Kl2lqLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the training process\n",
        "model = train_model(\n",
        "    model_class=Encoder,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    embedding_dim=config['embedding_dim'],\n",
        "    lr=config['learning_rate'],\n",
        "    checkpoint_path=CHECKPOINT_PATH,\n",
        "    total_epochs=35,\n",
        "    freeze_epochs=10,\n",
        ")\n",
        "#config['total_epochs']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "sdR3Kl3-lswy",
        "outputId": "3cb9d63b-9008-4a39-a0cf-ac4aa0f8daf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b5_lukemelas-1a07897c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b5_lukemelas-1a07897c.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 117M/117M [00:03<00:00, 37.0MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3071865707.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start the training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = train_model(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-188033605.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, train_loader, val_loader, embedding_dim, lr, checkpoint_path, total_epochs, freeze_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         model, optimizer, start_epoch, freeze_backbone = load_checkpoint(\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mmodel_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-309158182.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(model_class, optimizer_class, embedding_dim, lr, checkpoint_path)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0msaved_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    881\u001b[0m                 \u001b[0;34m\"loaded state dict contains a parameter group \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;34m\"that doesn't match the size of optimizer's group\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Define the path to your checkpoint file\n",
        "CHECKPOINT_FILE_PATH = os.path.join(DRIVE_PATH, '35th_epoch.pth')\n",
        "\n",
        "# 1. Instantiate the model with its correct architecture\n",
        "model = Encoder(embedding_dim=config['embedding_dim'])\n",
        "\n",
        "# 2. Check if the checkpoint file exists\n",
        "if os.path.exists(CHECKPOINT_FILE_PATH):\n",
        "    print(f\"‚úÖ Loading model from {CHECKPOINT_FILE_PATH}\")\n",
        "\n",
        "    # Load the entire checkpoint\n",
        "    checkpoint = torch.load(CHECKPOINT_FILE_PATH)\n",
        "\n",
        "    # Load ONLY the model's weights (state_dict)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    print(\"‚úÖ Model loaded successfully for evaluation.\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: Checkpoint file not found at {CHECKPOINT_FILE_PATH}\")\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "4yTJEl5uSIxm",
        "outputId": "9783e313-2c1b-45bd-df8a-3cb90f025590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loading model from /content/drive/MyDrive/35th_epoch.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3255301899.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Load the entire checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINT_FILE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Load ONLY the model's weights (state_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                         return _load(\n\u001b[0m\u001b[1;32m   1463\u001b[0m                             \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                             \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_weights_only_unpickler.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m                         \u001b[0;34mf\"Only persistent_load of storage is allowed, but got {pid[0]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                     )\n\u001b[0;32m--> 512\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLONG_BINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<I\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             typed_storage = load_tensor(\n\u001b[0m\u001b[1;32m   1929\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1898\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1900\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m             \u001b[0m_internal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \"\"\"\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mbackend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_privateuse1_backend_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_available\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0;34mf\"Attempting to deserialize object on a {backend_name.upper()} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;34mf\"device but torch.{backend_name}.is_available() is False. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Define the path to your checkpoint file\n",
        "CHECKPOINT_FILE_PATH = os.path.join(DRIVE_PATH, '35th_epoch.pth')\n",
        "\n",
        "# 1. Instantiate the model with its correct architecture\n",
        "model = Encoder(embedding_dim=config['embedding_dim'])\n",
        "\n",
        "# 2. Check if the checkpoint file exists\n",
        "if os.path.exists(CHECKPOINT_FILE_PATH):\n",
        "    print(f\"‚úÖ Loading model from {CHECKPOINT_FILE_PATH}\")\n",
        "\n",
        "    # Load the entire checkpoint, mapping all tensors to the CPU\n",
        "    checkpoint = torch.load(CHECKPOINT_FILE_PATH, map_location=torch.device('cpu'))\n",
        "\n",
        "    # Load ONLY the model's weights (state_dict)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    print(\"‚úÖ Model loaded successfully for evaluation.\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: Checkpoint file not found at {CHECKPOINT_FILE_PATH}\")\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11bebRit6fqH",
        "outputId": "349dbb41-d036-415f-f2f9-76f8cba376d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loading model from /content/drive/MyDrive/35th_epoch.pth\n",
            "‚úÖ Model loaded successfully for evaluation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (backbone): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        (2): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
              "              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (2): Conv2dNormActivation(\n",
              "              (0): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
              "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (2): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.005128205128205128, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
              "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (2): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.010256410256410256, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.015384615384615387, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.020512820512820513, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.02564102564102564, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.030769230769230774, mode=row)\n",
              "        )\n",
              "        (4): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0358974358974359, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.041025641025641026, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.046153846153846156, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.05128205128205128, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.05641025641025642, mode=row)\n",
              "        )\n",
              "        (4): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.06153846153846155, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
              "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0717948717948718, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.08205128205128205, mode=row)\n",
              "        )\n",
              "        (4): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.08717948717948719, mode=row)\n",
              "        )\n",
              "        (5): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.09230769230769231, mode=row)\n",
              "        )\n",
              "        (6): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.09743589743589744, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
              "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.10256410256410256, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.11282051282051284, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.11794871794871796, mode=row)\n",
              "        )\n",
              "        (4): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1230769230769231, mode=row)\n",
              "        )\n",
              "        (5): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1282051282051282, mode=row)\n",
              "        )\n",
              "        (6): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1056, bias=False)\n",
              "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1435897435897436, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.14871794871794874, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
              "        )\n",
              "        (4): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.158974358974359, mode=row)\n",
              "        )\n",
              "        (5): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1641025641025641, mode=row)\n",
              "        )\n",
              "        (6): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
              "        )\n",
              "        (7): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.17435897435897438, mode=row)\n",
              "        )\n",
              "        (8): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1794871794871795, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (7): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
              "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.18461538461538463, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(3072, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
              "              (1): BatchNorm2d(3072, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.18974358974358976, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(3072, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
              "              (1): BatchNorm2d(3072, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.19487179487179487, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (8): Conv2dNormActivation(\n",
              "        (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        (2): SiLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (1): AdaptiveAvgPool2d(output_size=1)\n",
              "  )\n",
              "  (head): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2048, out_features=128, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        # Extract label from the path\n",
        "        label = image_path.split(os.sep)[-2]\n",
        "\n",
        "        return image, label, image_path"
      ],
      "metadata": {
        "id": "5uG7rXCbwuIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_save_embeddings(model, image_paths, transform, output_path, batch_size=None):\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"‚úÖ Loading embeddings from {output_path}\")\n",
        "        data = torch.load(output_path)\n",
        "        return data['embeddings'], data['labels'], data['paths']\n",
        "\n",
        "    print(f\"‚è≥ Extracting embeddings and saving to {output_path}\")\n",
        "    dataset = FeatureDataset(image_paths, transform)\n",
        "\n",
        "    # Use the passed batch_size, or fall back to the default config\n",
        "    current_batch_size = batch_size if batch_size is not None else config['batch_size']\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=current_batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "    all_embeddings, all_labels, all_paths = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels, paths in tqdm(loader):\n",
        "            imgs = imgs.to(DEVICE)\n",
        "            embeddings = model(imgs).cpu()\n",
        "            all_embeddings.append(embeddings)\n",
        "            all_labels.extend(labels)\n",
        "            all_paths.extend(paths)\n",
        "\n",
        "    embeddings = torch.cat(all_embeddings)\n",
        "    labels = all_labels\n",
        "    paths = all_paths\n",
        "\n",
        "    torch.save({\n",
        "        'embeddings': embeddings,\n",
        "        'labels': labels,\n",
        "        'paths': paths\n",
        "    }, output_path)\n",
        "\n",
        "    print(f\"‚úÖ Embeddings saved to {output_path}\")\n",
        "    return embeddings, labels, paths\n",
        "\n",
        "def normalize_embeddings(embeddings):\n",
        "    return torch.nn.functional.normalize(embeddings, p=2, dim=1)"
      ],
      "metadata": {
        "id": "tt8CbgAqwuDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿßŸÖÿ®ÿØ€åŸÜ⁄Ø‚ÄåŸáÿß\n",
        "known_embeddings, known_labels, _ = extract_and_save_embeddings(\n",
        "    model, known_train_paths, transform_eval, os.path.join(DRIVE_PATH, 'known_embeddings.pt')\n",
        ")\n",
        "val_embeddings, val_labels, _ = extract_and_save_embeddings(\n",
        "    model, known_val_paths, transform_eval, os.path.join(DRIVE_PATH, 'val_embeddings.pt')\n",
        ")\n",
        "test_embeddings, test_labels, _ = extract_and_save_embeddings(\n",
        "    model, test_paths, transform_eval, os.path.join(DRIVE_PATH, 'test_embeddings.pt')\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKDRlIaWwuBK",
        "outputId": "b386fd46-b73a-47f0-a718-f8b7a0e5b441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loading embeddings from /content/drive/MyDrive/known_embeddings.pt\n",
            "‚úÖ Loading embeddings from /content/drive/MyDrive/val_embeddings.pt\n",
            "‚úÖ Loading embeddings from /content/drive/MyDrive/test_embeddings.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FINAL EVALUATION ---\n",
        "print(\"--- Starting Final Evaluation ---\")\n",
        "\n",
        "known_embeddings_norm = normalize_embeddings(known_embeddings).cpu().numpy()\n",
        "val_embeddings_norm = normalize_embeddings(val_embeddings).cpu().numpy()\n",
        "test_embeddings_norm = normalize_embeddings(test_embeddings).cpu().numpy()\n",
        "\n",
        "knn = NearestNeighbors(n_neighbors=1, metric='cosine')\n",
        "knn.fit(known_embeddings_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "3Uv7JrXewt-l",
        "outputId": "f15cef81-6c75-466e-f6a7-e13f21063a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Final Evaluation ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(metric='cosine', n_neighbors=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>NearestNeighbors</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=1)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the true known/unknown labels for the validation set\n",
        "val_true_labels = np.array([label if label in known_classes else 'unknown' for label in val_labels])\n",
        "val_dists, _ = knn.kneighbors(val_embeddings_norm)\n",
        "val_scores = -val_dists.min(axis=1) # Cosine similarity score\n",
        "\n",
        "threshold_range = np.linspace(min(val_scores), max(val_scores), 200)\n",
        "best_f1 = -1\n",
        "best_thr = 0\n",
        "\n",
        "for thr in tqdm(threshold_range, desc=\"üîç Optimizing Threshold\"):\n",
        "    val_pred_labels = np.where(val_scores > thr, 'known', 'unknown')\n",
        "    f1 = f1_score(val_true_labels, val_pred_labels, average='macro', zero_division=0)\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thr = thr\n",
        "\n",
        "print(f\"‚úÖ Best Threshold (optimized for F1 Score on Val): {best_thr:.4f} with F1 Score: {best_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEoGDJjOwt2r",
        "outputId": "fb8a0f6a-b9e9-43dc-f239-febbf69fa546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîç Optimizing Threshold: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 72.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Best Threshold (optimized for F1 Score on Val): -0.0621 with F1 Score: 0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FINAL EVALUATION ON TEST SET ---\n",
        "test_dists, test_indices = knn.kneighbors(test_embeddings_norm)\n",
        "\n",
        "final_preds = []\n",
        "for dists, indices in zip(test_dists, test_indices):\n",
        "    min_score = -dists.min()\n",
        "    if min_score >= best_thr:\n",
        "        closest_neighbor_idx = indices[dists.argmin()]\n",
        "        predicted_label = known_labels[closest_neighbor_idx]\n",
        "    else:\n",
        "        predicted_label = \"unknown\"\n",
        "    final_preds.append(predicted_label)\n",
        "\n",
        "true_labels_test = np.array([label if label in known_classes else \"unknown\" for label in test_labels])\n",
        "final_preds = np.array(final_preds)\n",
        "\n",
        "print(\"\\nüìä Final Test Results:\")\n",
        "print(\"Acc =\", accuracy_score(true_labels_test, final_preds))\n",
        "print(\"Prec =\", precision_score(true_labels_test, final_preds, average='macro', zero_division=0))\n",
        "print(\"Rec =\", recall_score(true_labels_test, final_preds, average='macro', zero_division=0))\n",
        "print(\"F1 =\", f1_score(true_labels_test, final_preds, average='macro', zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLVXfUq4xw6j",
        "outputId": "2f628a50-74cd-486e-8e89-4e1d5e511c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Final Test Results:\n",
            "Acc = 0.9102822580645161\n",
            "Prec = 0.9358916894027977\n",
            "Rec = 0.9038585443715571\n",
            "F1 = 0.9087611488449477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create binary labels for known vs unknown\n",
        "true_binary = ['known' if label in known_classes else 'unknown' for label in true_labels_test]\n",
        "pred_binary = ['known' if p in known_classes else 'unknown' for p in final_preds]\n",
        "\n",
        "# Create and display the confusion matrix with binary labels\n",
        "cm = confusion_matrix(true_binary, pred_binary, labels=['known', 'unknown'])\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['known', 'unknown'])\n",
        "disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix: Known vs Unknown (Test Set)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "X92p37o2x11_",
        "outputId": "48b3c065-5db6-43a8-bed5-ddcbd77626d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'final_preds', 'true_labels_test', 'test_paths', and 'known_classes' are already computed.\n",
        "# `known_classes` should be a set or list of all your known class names.\n",
        "\n",
        "print(\"\\n--- Known vs Unknown Misclassified Images with Details ---\")\n",
        "print(\"Image Path | Correct Label | Predicted Label | Error Type\")\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "\n",
        "# Create a list to store misclassified details\n",
        "misclassified_details_binary = []\n",
        "\n",
        "for i in range(len(final_preds)):\n",
        "    true_label = true_labels_test[i]\n",
        "    pred_label = final_preds[i]\n",
        "\n",
        "    is_true_known = true_label in known_classes\n",
        "    is_pred_known = pred_label in known_classes\n",
        "\n",
        "    # Check for misclassification between known and unknown\n",
        "    # This happens in two cases:\n",
        "    # 1. True label is known, but predicted label is unknown (False Negative)\n",
        "    # 2. True label is unknown, but predicted label is known (False Positive)\n",
        "    if is_true_known != is_pred_known:\n",
        "        error_type = \"\"\n",
        "        if is_true_known and not is_pred_known:\n",
        "            error_type = \"known -> unknown (False Negative)\"\n",
        "        elif not is_true_known and is_pred_known:\n",
        "            error_type = \"unknown -> known (False Positive)\"\n",
        "\n",
        "        misclassified_details_binary.append({\n",
        "            'path': test_paths[i],\n",
        "            'correct': true_label,\n",
        "            'predicted': pred_label,\n",
        "            'error_type': error_type\n",
        "        })\n",
        "\n",
        "# Print the detailed list of misclassified images\n",
        "if misclassified_details_binary:\n",
        "    num = 1\n",
        "    for item in misclassified_details_binary:\n",
        "        print(f\"{num} {item['path'][40:]} | {item['correct']} | {item['predicted']} | {item['error_type']}\")\n",
        "        num += 1\n",
        "else:\n",
        "    print(\"None found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cT8IBYd5icS",
        "outputId": "010c7ff4-0d0a-41bb-b089-8ba28e5698e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Known vs Unknown Misclassified Images with Details ---\n",
            "Image Path | Correct Label | Predicted Label | Error Type\n",
            "-------------------------------------------------------------------\n",
            "1 cattle_1300_DJI_0199.jpg | cattle_1300 | unknown | known -> unknown (False Negative)\n",
            "2 cattle_1700_DSCF7426.jpg | cattle_1700 | unknown | known -> unknown (False Negative)\n",
            "3 cattle_2000_DSCF8471.jpg | unknown | cattle_2100 | unknown -> known (False Positive)\n",
            "4 cattle_2000_DSCF8494.jpg | unknown | cattle_8095 | unknown -> known (False Positive)\n",
            "5 cattle_2220_DSCF1702.jpg | unknown | cattle_3100 | unknown -> known (False Positive)\n",
            "6 cattle_2220_DSCF1705.jpg | unknown | cattle_3100 | unknown -> known (False Positive)\n",
            "7 cattle_4369_DSCF6750.jpg | cattle_4369 | unknown | known -> unknown (False Negative)\n",
            "8 cattle_4399_DSCF6865.jpg | cattle_4399 | unknown | known -> unknown (False Negative)\n",
            "9 cattle_4399_DSCF6867.jpg | cattle_4399 | unknown | known -> unknown (False Negative)\n",
            "10 cattle_4421_DSCF8139.jpg | cattle_4421 | unknown | known -> unknown (False Negative)\n",
            "11 cattle_4421_DSCF8141.jpg | cattle_4421 | unknown | known -> unknown (False Negative)\n",
            "12 cattle_4549_DSCF6878.jpg | cattle_4549 | unknown | known -> unknown (False Negative)\n",
            "13 cattle_4716_DSCF9206.jpg | cattle_4716 | unknown | known -> unknown (False Negative)\n",
            "14 cattle_4685_DSCF6727.jpg | cattle_4685 | unknown | known -> unknown (False Negative)\n",
            "15 cattle_4820_DSCF8181.jpg | cattle_4820 | unknown | known -> unknown (False Negative)\n",
            "16 cattle_4770_DSCF6732.jpg | cattle_4770 | unknown | known -> unknown (False Negative)\n",
            "17 cattle_4985_DSCF9568.jpg | cattle_4985 | unknown | known -> unknown (False Negative)\n",
            "18 cattle_4915_DSCF9502.jpg | cattle_4915 | unknown | known -> unknown (False Negative)\n",
            "19 cattle_5009_DSCF9154.jpg | cattle_5009 | unknown | known -> unknown (False Negative)\n",
            "20 cattle_5009_DSCF9158.jpg | cattle_5009 | unknown | known -> unknown (False Negative)\n",
            "21 cattle_5009_DSCF9163.jpg | cattle_5009 | unknown | known -> unknown (False Negative)\n",
            "22 cattle_5090_DSCF7819.jpg | unknown | cattle_4951 | unknown -> known (False Positive)\n",
            "23 cattle_5090_DSCF7822.jpg | unknown | cattle_4951 | unknown -> known (False Positive)\n",
            "24 cattle_5090_DSCF7824.jpg | unknown | cattle_4951 | unknown -> known (False Positive)\n",
            "25 cattle_5028_DSCF8277.jpg | cattle_5028 | unknown | known -> unknown (False Negative)\n",
            "26 cattle_5132_DSCF7743.jpg | cattle_5132 | unknown | known -> unknown (False Negative)\n",
            "27 cattle_5132_DSCF7745.jpg | cattle_5132 | unknown | known -> unknown (False Negative)\n",
            "28 cattle_5132_DSCF7746.jpg | cattle_5132 | unknown | known -> unknown (False Negative)\n",
            "29 cattle_5153_DSCF9128.jpg | cattle_5153 | unknown | known -> unknown (False Negative)\n",
            "30 cattle_5153_DSCF9130.jpg | cattle_5153 | unknown | known -> unknown (False Negative)\n",
            "31 cattle_5249_DSCF7442.jpg | cattle_5249 | unknown | known -> unknown (False Negative)\n",
            "32 cattle_5249_DSCF7454.jpg | cattle_5249 | unknown | known -> unknown (False Negative)\n",
            "33 cattle_5234_DSCF9060.jpg | cattle_5234 | unknown | known -> unknown (False Negative)\n",
            "34 cattle_5207_DSCF8806.jpg | cattle_5207 | unknown | known -> unknown (False Negative)\n",
            "35 cattle_5170_DSCF7668.jpg | cattle_5170 | unknown | known -> unknown (False Negative)\n",
            "36 cattle_5215_DSCF9134.jpg | cattle_5215 | unknown | known -> unknown (False Negative)\n",
            "37 cattle_5215_DSCF9146.jpg | cattle_5215 | unknown | known -> unknown (False Negative)\n",
            "38 cattle_5215_DSCF9189.jpg | cattle_5215 | unknown | known -> unknown (False Negative)\n",
            "39 cattle_5355_DSCF7964.jpg | cattle_5355 | unknown | known -> unknown (False Negative)\n",
            "40 cattle_5355_DSCF7965.jpg | cattle_5355 | unknown | known -> unknown (False Negative)\n",
            "41 cattle_5297_DSCF7443.jpg | cattle_5297 | unknown | known -> unknown (False Negative)\n",
            "42 cattle_5297_DSCF7444.jpg | cattle_5297 | unknown | known -> unknown (False Negative)\n",
            "43 cattle_5298_DSCF8097.jpg | cattle_5298 | unknown | known -> unknown (False Negative)\n",
            "44 cattle_5604_DSCF6929.jpg | cattle_5604 | unknown | known -> unknown (False Negative)\n",
            "45 cattle_5630_DSCF7969.jpg | cattle_5630 | unknown | known -> unknown (False Negative)\n",
            "46 cattle_5717_DSCF7509.jpg | unknown | cattle_9029 | unknown -> known (False Positive)\n",
            "47 cattle_5717_DSCF7510.jpg | unknown | cattle_9029 | unknown -> known (False Positive)\n",
            "48 cattle_5717_DSCF7519.jpg | unknown | cattle_4951 | unknown -> known (False Positive)\n",
            "49 cattle_5697_DSCF9348.jpg | unknown | cattle_5275 | unknown -> known (False Positive)\n",
            "50 cattle_5677_DSCF7459.jpg | cattle_5677 | unknown | known -> unknown (False Negative)\n",
            "51 cattle_5925_DSCF6910.jpg | cattle_5925 | unknown | known -> unknown (False Negative)\n",
            "52 cattle_5925_DSCF6912.jpg | cattle_5925 | unknown | known -> unknown (False Negative)\n",
            "53 cattle_5816_DSCF7730.jpg | unknown | cattle_4951 | unknown -> known (False Positive)\n",
            "54 cattle_5816_DSCF7738.jpg | unknown | cattle_9773 | unknown -> known (False Positive)\n",
            "55 cattle_6161_DSCF7340.jpg | unknown | cattle_6237 | unknown -> known (False Positive)\n",
            "56 cattle_6161_DSCF7345.jpg | unknown | cattle_4951 | unknown -> known (False Positive)\n",
            "57 cattle_6161_DSCF7349.jpg | unknown | cattle_4951 | unknown -> known (False Positive)\n",
            "58 cattle_6189_DSCF7249.jpg | cattle_6189 | unknown | known -> unknown (False Negative)\n",
            "59 cattle_6167_DSCF9102.jpg | unknown | cattle_9798 | unknown -> known (False Positive)\n",
            "60 cattle_6167_DSCF9111.jpg | unknown | cattle_6237 | unknown -> known (False Positive)\n",
            "61 cattle_6167_DSCF9113.jpg | unknown | cattle_9798 | unknown -> known (False Positive)\n",
            "62 cattle_6196_DSCF8922.jpg | cattle_6196 | unknown | known -> unknown (False Negative)\n",
            "63 cattle_6313_DSCF8789.jpg | cattle_6313 | unknown | known -> unknown (False Negative)\n",
            "64 cattle_6331_DSCF8768.jpg | cattle_6331 | unknown | known -> unknown (False Negative)\n",
            "65 cattle_6505_DSCF6992.jpg | cattle_6505 | unknown | known -> unknown (False Negative)\n",
            "66 cattle_9801_DSCF8587.jpg | unknown | cattle_9021 | unknown -> known (False Positive)\n",
            "67 cattle_9635_DSCF8600.jpg | unknown | cattle_4951 | unknown -> known (False Positive)\n",
            "68 cattle_9736_DSCF8518.jpg | unknown | cattle_9798 | unknown -> known (False Positive)\n",
            "69 cattle_9736_DSCF8520.jpg | unknown | cattle_9798 | unknown -> known (False Positive)\n",
            "70 cattle_9736_DSCF8523.jpg | unknown | cattle_9029 | unknown -> known (False Positive)\n",
            "71 cattle_9736_DSCF8524.jpg | unknown | cattle_9029 | unknown -> known (False Positive)\n",
            "72 cattle_9634_DSCF8589.jpg | unknown | cattle_9029 | unknown -> known (False Positive)\n",
            "73 cattle_9634_DSCF8590.jpg | unknown | cattle_9798 | unknown -> known (False Positive)\n",
            "74 cattle_9634_DSCF8594.jpg | unknown | cattle_9798 | unknown -> known (False Positive)\n",
            "75 cattle_9634_DSCF8600.jpg | unknown | cattle_9798 | unknown -> known (False Positive)\n",
            "76 cattle_9634_DSCF8610.jpg | unknown | cattle_9021 | unknown -> known (False Positive)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"--- Starting Final Evaluation (Per-Cow Prediction) ---\")\n",
        "\n",
        "# Assuming embeddings and labels are already loaded\n",
        "# known_embeddings_norm = normalize_embeddings(known_embeddings).cpu().numpy()\n",
        "# val_embeddings_norm = normalize_embeddings(val_embeddings).cpu().numpy()\n",
        "# test_embeddings_norm = normalize_embeddings(test_embeddings).cpu().numpy()\n",
        "\n",
        "# 1. Optimize Threshold on Validation Set (unchanged from previous step)\n",
        "knn = NearestNeighbors(n_neighbors=1, metric='cosine')\n",
        "knn.fit(known_embeddings_norm)\n",
        "\n",
        "val_true_labels = np.array([label if label in known_classes else 'unknown' for label in val_labels])\n",
        "val_dists, _ = knn.kneighbors(val_embeddings_norm)\n",
        "val_scores = -val_dists.min(axis=1)\n",
        "\n",
        "threshold_range = np.linspace(min(val_scores), max(val_scores), 200)\n",
        "min_total_errors = float('inf')\n",
        "best_thr = 0\n",
        "\n",
        "for thr in tqdm(threshold_range, desc=\"üîç Optimizing Threshold\"):\n",
        "    val_pred_labels = np.where(val_scores > thr, 'known', 'unknown')\n",
        "    cm = confusion_matrix(val_true_labels, val_pred_labels, labels=['known', 'unknown'])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    total_errors = fp + fn\n",
        "    if total_errors < min_total_errors:\n",
        "        min_total_errors = total_errors\n",
        "        best_thr = thr\n",
        "\n",
        "print(f\"‚úÖ Best Threshold (optimized for minimizing FP+FN on Val): {best_thr:.4f}\")\n",
        "\n",
        "# 2. Per-Cow Prediction on Test Set\n",
        "test_dists, test_indices = knn.kneighbors(test_embeddings_norm)\n",
        "image_preds = []\n",
        "for dists, indices in zip(test_dists, test_indices):\n",
        "    min_score = -dists.min()\n",
        "    if min_score >= best_thr:\n",
        "        closest_neighbor_idx = indices[dists.argmin()]\n",
        "        predicted_label = known_labels[closest_neighbor_idx]\n",
        "    else:\n",
        "        predicted_label = \"unknown\"\n",
        "    image_preds.append(predicted_label)\n",
        "\n",
        "# 3. Aggregate predictions per cow (majority vote)\n",
        "unique_test_labels = list(set(test_labels))\n",
        "final_cow_preds = []\n",
        "final_cow_true_labels = []\n",
        "\n",
        "for cow_id in tqdm(unique_test_labels, desc=\"üó≥Ô∏è Aggregating per-cow predictions\"):\n",
        "    cow_indices = [i for i, label in enumerate(test_labels) if label == cow_id]\n",
        "    cow_image_preds = [image_preds[i] for i in cow_indices]\n",
        "\n",
        "    # Get the majority vote. If it's a known cow, the true label is its ID.\n",
        "    if cow_id in known_classes:\n",
        "        true_label = cow_id\n",
        "    else:\n",
        "        true_label = \"unknown\"\n",
        "\n",
        "    # Majority vote\n",
        "    if cow_image_preds:\n",
        "        majority_vote = Counter(cow_image_preds).most_common(1)[0][0]\n",
        "        final_cow_preds.append(majority_vote)\n",
        "        final_cow_true_labels.append(true_label)\n",
        "\n",
        "# 4. Final evaluation with per-cow results\n",
        "print(\"\\nüìä Final Test Results (Per-Cow):\")\n",
        "print(\"Acc =\", accuracy_score(final_cow_true_labels, final_cow_preds))\n",
        "\n",
        "# Create binary labels for known vs unknown for the confusion matrix\n",
        "true_binary_cows = ['known' if label in known_classes else 'unknown' for label in final_cow_true_labels]\n",
        "pred_binary_cows = ['known' if p in known_classes else 'unknown' for p in final_cow_preds]\n",
        "\n",
        "# Compute and display the confusion matrix\n",
        "cm = confusion_matrix(true_binary_cows, pred_binary_cows, labels=['known', 'unknown'])\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['known', 'unknown'])\n",
        "disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix: Known vs Unknown (Per-Cow)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "kOuS7UVtTinP",
        "outputId": "eed9c927-8e75-400e-db95-aefa1feebf2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Final Evaluation (Per-Cow Prediction) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîç Optimizing Threshold: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 583.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Best Threshold (optimized for minimizing FP+FN on Val): -0.0368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üó≥Ô∏è Aggregating per-cow predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:00<00:00, 8814.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Final Test Results (Per-Cow):\n",
            "Acc = 0.8731343283582089\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}